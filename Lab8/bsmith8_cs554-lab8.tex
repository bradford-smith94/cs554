% Bradford Smith
% bsmith8_cs554-lab8.tex
% 11/20/2017
%===============

% global document styles =======================================================
\documentclass[12pt, letterpaper]{homework}

\usepackage{color}
\usepackage{etoolbox}
\AtBeginEnvironment{quote}{\small\color{gray}}

\author{Bradford Smith}
\assignment{CS 554 Lab 8}
\title{}
\date{\today}

% document begins here =========================================================
\begin{document}
\maketitle

\section*{Scenario 1: Logging}

\begin{quote}
    In this scenario, you are tasked with creating a logging server for any number
    of other arbitrary pieces of technologies.

    Your logs should have some common fields, but support any number of
    customizeable fields for an individual log entry. You should be able to
    effectively query them based on any of these fields.

    How would you store your log entries? How would you allow users to submit log
    entries? How would you allow them to query log entries? How would you allow them
    to see their log entries? What would be your web server?
\end{quote}

I would store log entries in a database, probably MongoDB, in order to
facilitate easy lookups. Users would be able to submit log entries through a
form. This form would have required fields such as time/date, the program
sending or generating the log entry and a log message. To allow for custom
fields users would be able to click a `plus' button that would add a custom
field, essentially just two text inputs for entering a lookup key and a value.
For the custom fields the keys would have to be unique in order for the form to
validate. In order to query log entries users would be presented with a search
box for the query string and a set of radio buttons to select the key to search
against. If the `custom key' radio button is selected a hidden text input should
appear allowing the user to specify the custom key. Additionally a paginated
view of log entries would be available for the users. For this I would probably
choose Node as my web server because I have the most experience with it.

\pagebreak{}
\section*{Scenario 2: Expense Reports}

\begin{quote}
    In this scenario, you are tasked with making an expense reporting web
    application.

    Users should be able to submit expenses, which are always of the same data
    structure: \code{id}, \code{user}, \code{isReimbursed}, \code{reimbursedBy},
    \code{paidOn}, and \code{amount}.

    When an expense is reimbursed you will generate a PDF and email it to the user
    who submitted the expense.

    How would you store your expenses? What web server would you choose, and why?
    How would you handle the emails? How would you handle PDF generation? How are
    you going to handle all the templating for the web application?
\end{quote}

I would store the expenses in a database, again probably MongoDB\@. I would
choose Node as my webserver because I have the most experience with it and it
pairs well with MongoDB\@. After searching for a Node module to handle emails I
found that Nodemailer seems to work well, so I would try to use that for sending
emails. I would choose \LaTeX{} for generating PDFs because I already use it for
most of my work, it should be easy to setup an `expense report' class to be
easily filled in with data from an HTML form if there doesn't already exist a
class that will fit the needs. \LaTeX{} will handle any templating needed for
the PDF files, as for templating on the web application itself I would probably
use EJS mostly because it is pretty simple and the only one I can think of off
the top of my head.

\pagebreak{}
\section*{Scenario 3: A Twitter Streaming Safety Service}

\begin{quote}
    In this scenario, you are tasked with creating a service for you local Police
    Department that keeps track of Tweets within your area and scans for keywords to
    trigger an investigation.

    This application comes with several parts:
    \begin{itemize}
        \item An online website to CRUD combinations of keywords to add to your
            trigger. For example, it would alert when a Tweet contains the words
            (\code{fight} or \code{drugs}) AND (\code{SmallTown USA HS} or
            \code{SMUHS}).
        \item An email alerting system to alert different officers depending on the
            contents of the Tweet, who Tweeted it, etc.
        \item A text alert system to inform officers for critical triggers (triggers
            that meet a combination that is marked as extremely important to note).
        \item A historical database to view possible incidents (Tweets that
            triggered an alert) and to mark its investigation status.
        \item A historical log of \textit{all} Tweets to retroactively search
            through.
        \item A streaming, online incident report. This would allow you to see
            Tweets as they are parsed and see their threat level. This updates in
            real time.
        \item A long term storage of all the media used by any Tweets in your area
            (pictures, snapshots of the URL, etc).
    \end{itemize}

    Which Twitter API do you use? How would you build this so its expandable to
    beyond your local precinct? What would you do to make sure that this system is
    constantly stable? What would be you web server technology? What databases would
    you use for triggers? For the historical log of Tweets? How would you handle the
    real time, streaming incident report? How would you handle storing all the media
    that you have to store as well? What web server technology would you use?
\end{quote}

I would use the Twitter Search API in order to pull in recent Tweets. To make
sure the application is expandable I would keep the server generalized so that
other towns or departments will be able to use it easily. By relying as much as
possible on other services like cloud storage expandability is made easier. In
order to make sure the system is constantly stable I would try to use
technologies and services with support available. For my web server I would use
\@.NET Core on Windows IIS solely for the fact that the departments will have a
support staff to go to with issues about their web server. For databases I would
probably choose redis for the triggers because of it's speed, but MySQL for the
historical log because of it's stability and common use. For a real time
streaming incident report I would opt for a websocket client that subscribes to
events corresponding to new Tweet. The media archive I would try to store with
Microsoft, probably OneDrive or whatever an enterprise equivalent would be,
again chosen for the support staff and stability.

\pagebreak{}
\section*{Scenario 4: A Mildly Interesting Mobile Application}

\begin{quote}
    In this scenario, you are tasked with creating the web server side for a mobile
    application where people take pictures of mildly interesting things and upload
    them. The mobile application allows users to see mildly interesting pictures in
    their geographical location.

    Users must have an account to use this service. Your backend will effectively
    amount to an API and a storage solution for CRUD users, CRUD `interesting
    events', as well as an administrative dashboard for managing content.

    How would you handle the geospatial nature of your data? How would you store the
    images, both for the long term, cheap storage and for short term, fast
    retrieval? What would you write your API in? What would be your database?
\end{quote}

Because of the geospatial nature of the data I would try to cache items near a
user's location or last searched location to improve search response times. I
would also try to sort the data by location as best as possible rather than
alphabetically or by time or other identifier. Images could be stored for the
long term using a cloud storage platform such as AWS S3, OneDrive, Google Drive
or Dropbox. For the short term commonly searched or used images could be saved
in a cache, such as redis, for quick retrieval. I would probably write my API in
NodeJS and use MongoDB as my database.

\end{document}

